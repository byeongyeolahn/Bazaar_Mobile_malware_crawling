from logging import exception
import re
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
import time
import argparse
import pymysql
import os



def crawling():
    print("[+] My SQL 연결 시도......")
    #my sql 연결
    conn = pymysql.connect(host='127.0.0.1', user = 'root', password='dptmzbdpf',db = 'malware_apk', charset='utf8')
    cursor = conn.cursor()
    print("[+] My SQL 연결 성공!")
    # 기존 해시값 가져오기
    file_hash = []
    cursor.execute("SELECT * FROM md5")
    for q in cursor.fetchall():
        temp = q[1]
        file_hash.append(temp)
    file_name = []


    options = Options()

    # 옵션 설정
    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'
    options.add_argument('user-agent=' + user_agent)
    options.add_experimental_option("excludeSwitches", ["enable-logging"])
    options.add_experimental_option('prefs', {
        "download.default_directory": args.d,
        "download.prompt_for_download": False,
        "download.directory_upgrade": True,
        "safebrowsing.enabled": True})
    driver = webdriver.Chrome(options=options)
 
    # 초기 검색어 입력
    query = args.s

    # URL 접속
    url1 = 'https://bazaar.abuse.ch/browse/'
    driver.get(url1)
    time.sleep(10)

    search_tab = driver.find_element(By.CSS_SELECTOR, '#search')
    search_tab.send_keys(query)
    search_tab.send_keys(Keys.ENTER)
    time.sleep(3)

    # apk 파일들 sha256 값 모으기


 
    # for i in range(1,4):
    for k in range(2,6):
        driver.find_element(By.XPATH, '//*[@id="samples_paginate"]/ul/li[{}]/a'.format(k)).click()
        for i in range(1,251):
            tag_td = driver.find_element(By.CSS_SELECTOR, '#samples > tbody > tr:nth-child({}) > td:nth-child(2) > a'.format(i))
            tag_href = tag_td.get_attribute('href')
            file_name.append(tag_href)
    print("[+] 파일 해시 정보 수집 완료")
    
    for h in range(len(file_name)):
        url_list = file_name[h]
        driver.get(url_list)
        # 중복 검사
        file_md5 = driver.find_element(By.ID, 'md5_hash')
        if file_md5.text in file_hash:
            print(file_name[h] + "가 이미 존재합니다.")
            continue

        file_hash.append(file_md5.text)
        sql = "INSERT INTO md5(md5_hash) values(%s)"
        val = (file_hash[h])
        cursor.execute(sql, val)
        # 중복 아닐 경우 다운 진행 
        driver.find_element(By.XPATH, '/html/body/main/table/tbody/tr[7]/td/a').click()
        
        tag_div = driver.find_element(By.CSS_SELECTOR, 'body > main > div.container.text-center')
        tag_button = tag_div.find_element(By.TAG_NAME, 'button')
        tag_id = tag_button.get_attribute('id')
        driver.find_element(By.XPATH, '//*[@id="{}"]'.format(tag_id)).click()
        conn.commit()
        time.sleep(1)

    conn.close()

# def file_unzip():
#     basic_dir = '압축해제 대상 폴더'

#     file_list = os.listdir(basic_dir)
#     file_name = []
#     for i in range(len(file_list)):
#         try:
#             file_name.append(basic_dir + str(file_list[i]))
#             unzip.unzip_fun(file_name[i])
#         except:
#             print(str(file_name[i])+ '해제 실패')


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description = "Bazaar Malware Crawling \n ")
    parser.add_argument('-d', type=str, help = '-d D:\\APK 샘플\\Bazaar')
    parser.add_argument('-s', type=str, help = '-s tag:apk')
    
    args = parser.parse_args()
    crawling()
    # file_unzip()
